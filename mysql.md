# 分库分表

## 问题分析

采用单数据库进行数据存 储，存在以下性能瓶颈：

1. IO瓶颈：热点数据太多，数据库缓存不足，产生大量磁盘IO，效率较低。 请求数据太多，带宽不够，网络IO瓶颈。 
2. CPU瓶颈：排序、分组、连接查询、聚合统计等SQL会耗费大量的CPU资源，请求数太多，CPU出现瓶颈。

为了解决上述问题，我们需要对数据库进行分库分表处理。

分库分表的中心思想：将数据分散存储，使得单一数据库/表的数据量变小来缓解单一数据库的性能问题，从而达到提升数据库性能的目的。

## 拆分策略

拆分的维度：垂直拆分和水平拆分。拆分的粒度：为分库和分表。

### 垂直拆分

#### 垂直分库

<img src="https://wsb-typora-picture.oss-cn-chengdu.aliyuncs.com/picgo/202503131234255.png" alt="image-20250313123411147" style="zoom: 50%;" />

垂直分库：以表为依据，根据业务将不同表拆分到不同库中。

 特点： 每个库的表结构都不一样。 每个库的数据也不一样。 所有库的并集是全量数据。

#### 垂直分表

<img src="https://wsb-typora-picture.oss-cn-chengdu.aliyuncs.com/picgo/202503131234252.png" alt="image-20250313123457193" style="zoom:50%;" />

垂直分表：以字段为依据，根据字段属性将不同字段拆分到不同表中。

 特点： 每个表的结构都不一样。 每个表的数据也不一样，一般通过一列（主键/外键）关联。 所有表的并集是全量数据

### 水平拆分

#### 水平分库

<img src="https://wsb-typora-picture.oss-cn-chengdu.aliyuncs.com/picgo/202503131238463.png" alt="image-20250313123830423" style="zoom: 50%;" />

水平分库：以字段为依据，按照一定策略，将一个库的数据拆分到多个库中。 

特点： 每个库的表结构都一样。 每个库的数据都不一样。 所有库的并集是全量数据。

#### 水平分表

<img src="https://wsb-typora-picture.oss-cn-chengdu.aliyuncs.com/picgo/202503131239643.png" alt="image-20250313123922573" style="zoom:50%;" />

水平分表：以字段为依据，按照一定策略，将一个表的数据拆分到多个表中。 

特点： 每个表的表结构都一样。 每个表的数据都不一样。 所有表的并集是全量数据。

# SQL性能分析

- 首先，通过`show status`命令查看增删改查频次。如果是以查询为主，则考虑对索引进行优化。
- 然后，通过慢查询日志，定位到具体需要对哪些查询语句进行优化。
- 然后，通过`show profiles`查看每一条SQL的耗时基本情况，再通过`show profile for query query_id`查看指定query_id的SQL语句各个阶段的耗时情况。
- 然后，通过`explain`关键字sql语句的详细信息。

# 执行一条select语句，MySQL的执行流程

![image-20250725143515022](https://wsb-typora-picture.oss-cn-chengdu.aliyuncs.com/picgo/202507251435568.png)

首先，mysql的总体架构分为两层，分别是server层和存储引擎层。sever层负责建立连接、分析和执行sql语句。mysql的大多数功能都是在这里实现。存储引擎层负责数据的存储和提取。而且，由于mysql支持多种存储引擎，比如InnoDB、MyISAM或者Memory，那么，这些存储引擎就会共用一个sever层。这是mysql的一个总体架构，具体的sql执行过程都是在这么一个架构下执行的。首先，当我们要使用mysql时候，第一步肯定是连接mysql服务，这里sever层有一个连接器，他会根据你输入的ip地址和端口号进行tcp的三次握手连接，连接上后再验证我们的用户名和密码对不对。如果都正确的话，那连接器就获得了这个用户的权限，然后保存起来，后续所有的操作都会基于这个权限进行。然后，对于查询操作，mysql会有一个查询缓存的操作，缓存里都是key-value的数据，key是sql查询语句，value是查询的结果，如果命中缓存的话，就直接给你返回value值，如果没有命中，那就执行下面的正常流程，然后执行完后把这个sql查询语句和结果写入到这个缓存中。但是，有时候查询缓存这一步也挺鸡肋的，比如，对于一些更新比较频繁的表，只要这个表有更新操作，那么就会清空缓存。所以这里的查询缓存命中率就会很低。所以mysql从8.0开始就不会再走查询缓存这一步。然后，如果不走缓存，下面会有一个解析器对sql语句进行解析，解析器主要由两步骤组成，分别是词法分析和语法分析，词法分析就是根据你输入的字符串识别出关键字和非关键字，比如select关键字、from关键字和where关键字。语法分析会根据词法分析的结果，判断符不符合sql语法规则，如果正确的话，就会构建一个sql语法树，有了这个语法树，后面的执行过程就能很方便的拿到这条sql语句的sql类型、表名、字段名、where条件这些信息。有一点要注意就是，判断表或者字段存不存在，比如你的字段或者表名输入错了，不是在解析器这一步判断的，是在下一步的预处理器进行判断的。并且，把select *中的这个符号扩展为表上的所有列名也是预处理器的工作。接下来会有一个优化器，它会给sql查询语句制定一个执行计划，就是把你这个sql语句具体要怎么查的一个执行方案确定下来，比如，是不是要走索引，多个索引走哪个索引。都是在优化器确定下来的。我们通过explain命令查到的那个执行计划就是这里的优化器给出的。里面有一个possible_keys字段，会给出这条语句里有可能走的索引，还有个key字段，会给出具体是走哪个字段。如果key=null，那就代表没走索引，就会走全表扫描，这时候有个字段type这里就会显示ALL，就代表走的是全表扫描。确定了执行计划后，mysql就要开始真正执行sql语句了，这个过程是由执行器完成的，他会调用存储引擎层的接口去完成。比如，如果是全表扫描，那么存储引擎会从表第一条记录读，如果不符合就跳过，如果符合，就把这条记录发送回客户端，然后，又回来再接着查，也就是说执行器查询这一步他是一个while循环的过程，一直把整个表查完为止。

# redo log

首先，redolog是 Innodb 存储引擎生成的，它主要是为了防止断电导致的数据丢失问题，去保证事务的持久性。比如，更新一条数据时候，InnoDB存储引擎回先更新缓冲池中对应的那一页的数据，然后把那一页标记为脏页，然后把你对这一页做的修改记录到redo log buffer中，然后通过设置的刷盘策略把redo log buffer中的内容持久化到磁盘的redo log文件中，这时候，虽然脏页还没有持久化，但更新也算完成了。之后，存储引擎再把脏页刷新到磁盘里。刚刚说的这种，先写日志，再把数据刷新到磁盘，就是WAL技术。如果在刷新脏页过程中系统崩溃了，那mysql就可以在重启后根据redo log中的内容给把数据恢复到最新状态。如果在刷盘redolog buffer的过程中崩溃，那丢失的数据多少就要根据你设置的刷盘策略来看了。

## 刷盘策略

![image-20250725171747697](https://wsb-typora-picture.oss-cn-chengdu.aliyuncs.com/picgo/202507251717844.png)

主要会在4个时机进行刷盘，第一个是，当MySQL正常关闭时，它会进行刷盘。第二个是，当redo log buffer中的写入量大于redo log buffer的内存空间的一半时，也会进行刷盘。第三个是，InnoDB的后台线程每隔一秒，会把redo log buffer中的内容持久化到磁盘中。第四个是，默认每次事务提交时候都刷盘。最后这个可以通过一个参数叫innodb_flush_log_at_trx_commit进行控制。默认值是1，就是每次事务提交时刷盘。还能设置0和2。为0的时候，每次事务提交时，不会主动触发刷盘操作，而是等刚刚说的那个每隔一秒刷盘一次的后台线程，通过它，调用write()方法先把 redo log buffer中的内容写到操作系统的Page Cache中，然后再调用fsync()方法刷盘到磁盘中。所以，这种刷盘策略，在极端情况下会导致丢失这一秒内的所有事务数据。设置参数值为2的时候，每次事务提交的时候，只是先把redo log buffer中的内容通过write()方法写到操作系统的Page Cache中，还没有刷盘到磁盘中，然后每隔一秒通过那个后台线程调用fsync()方法把Page Cache中的内容刷盘到磁盘中。所以，这种策略比参数为0的策略稍微安全点，因为当mysql进程崩溃的时候，他不会丢失数据，只有当操作系统都崩溃了，他才会丢失上一秒中的数据。所以，从数据安全性来看，最安全的肯定是参数设置为1的时候，每次事务提交都会刷盘，最多丢失这一次事务的数据，然后是参数2，最后是参数0。如果从性能方面看的话，参数设置为0时候肯定是最快的，因为它每次事务提交时候只用先写到内存中的redo log buffer中，然后是参数2，最后是参数1。所以，安全和性能没办法都做到极致，要根据业务权衡一下。

## redo log文件写满怎么办？

默认情况下，有一个redo log文件组，有两个redo log文件组成，然后用循环写的方式工作。比如，先从文件0开始写，写满后，切换到文件1开始写，再写满后，又切换回文件0。这里有个问题就是文件0已经是满的了，写不了了怎么办？这里InnoDB用checkpoint机制去记录当前要擦除的位置。就是redo log是为了防止缓冲池中的脏页数据丢失设计的嘛，那么如果有的脏页数据已经刷盘了，已经持久化了，那么redo log中对应的那部分记录也就没意义了，就可以把那部分内容删除掉，checkpoint记录的就是可以从哪里开始删除，就是这个位置之前的日志都可以被删除。还有一个write pos来记录当前日志写到的位置，那么要写新日志时候就从这个位置开始写。所以，当write pos追上checkpoint，他俩记录的位置一样的时候，就意味着redo log日志满了，这个时候mysql就会被阻塞。然后等将缓冲池中的一部分脏页刷盘后，擦除了一部分日志后，再恢复运行。

# undo log

首先，undo log是 Innodb 存储引擎生成的，它主要是为了保证事务的原子性。比如，在进行增删改操作时候，执行了一半，还没有提交事务，这时候mysql崩了，就可以通过undo log日志进行回滚操作，把数据都回滚到事务之前。比如，当插入一条记录时候，可以把这条记录的主键值记录下来，回滚时候把这个主键值对应的记录删除掉就好。删除一条记录时候，得把这条记录的内容全都记下来，回滚时候把这些内容再重新插入回去。更新一条记录时候，把更新的旧值记下来，回滚时候再把旧值更新回去就好了。这样就可以保证事务的原子性。

# bin log

首先，binlog是mysql的server层生成的。它主要是记录了所有的表结构或者数据变更的日志。比如，在一个事务里，当执行一条更新操作后，Server层就会生成一条 binlog，然后，等之后事务提交的时候，把事务执行过程中产生的所有binlog统一写入到binlog文件里。然后，它写入的文件格式主要有三种可以选择，分别是STATEMENT这个是默认模式，还有ROW和 MIXED。STATEMENT模式下，它记录的是逻辑sql，比如，你执行了一条更新语句，那他就会把这条语句原模原样的记下来。这种模式下有一个动态函数的问题，就是比如你在sql语句中用了uuid或者now这样的函数，那么在主从复制中，从库执行这条sql语句得到的结果就会的主库不一样。row模式它就不再记录逻辑sql了，它会记录数据最终被修改成什么样。比如，有一条更新sql语句，改变了好几行数据，那他就会把这几行改变之后的结果都记录下来，这样就不会出现刚刚说的动态函数的问题了。但这样有可能导致binlog文件太大。还有一种就是mixed模式，就是把这两种模式混合起来用。

## 为什么有bin log还要redo log？

他俩的用途不一样，binlog是用于备份恢复和主从复制，redolog是用于掉电宕机这些故障的恢复。比如，极端一点，如果不小心把整个数据库的数据都删除了，那么就只能拿binlog恢复。因为binlog的文件是追加写，他保存的是全量信息，也就是保存了所有数据变更的情况。但是redolog是循环写，它会边写边把已经持久化的部分日志擦除掉。

## 主从复制

主从复制它主要是将数据库的DDL数据定义语言和DML数据操作语言通过binlog二进制日志传到从库上，然后在从库上对这些日志重新执行一下，让从库和主库的数据保持同步。而且这里mysql也支持一个从库再以作为其他从库的的主库，从而实现链状复制。通过主库和从库的设定，一方面，他可以把数据备份到从库，那么当主库出现问题，就能快速切换到从库来提供服务。还有一方面，它能够实现读写分离，比如把写操作放到主库去执行，读操作分散到从库去执行，这样就能减少主库的压力，并且就算你有一个写请求会锁表或者锁记录，也不会影响读请求的执行。它具体实现过程的话是这样的，首先就是主库会在提交事务时候写binlog日志，然后从库会用一个IO线程去接收这个binlog日志，把日志写到从库的relaylog中继日志里。然后从库还有一个sql线程去读中继日志，把binlog里的东西都回放出来，这样就实现了主从数据一致。并且，这个过程默认是异步执行的，就是说主库提交事务的那个线程不会阻塞等待binlog同步就直接给客户端返回了。所以这种模式有可能在主库宕机时候发生数据丢失的问题。还有一种是同步复制，就是主库要阻塞等所有从库返回复制成功的响应后才给客户端返回结果。这种的性能就很慢了。还有一种是半同步复制，就是主库不用等所有从库返回响应，只要等到一部分返回响应了就可以往下执行。这样性能不会太差而且也能保证至少有一个从库有最新的数据，就不会发生数据丢失的风险。

## binlog刷盘

![image-20250728155055160](https://wsb-typora-picture.oss-cn-chengdu.aliyuncs.com/picgo/202507281551254.png)

mysql的server层给每个线程分配了一个binlog cache用来缓冲binlog文件内容，在事务执行的过程中，会先把binlog日志写到这个binlog cache中，然后事务提交的时候，server层的执行器再把binlog cache的内容写到binlog文件中。而且，这里把binlog cache的内容写到binlog文件中这个过程中，同一个事务的binlog是不能拆开的。因为，如果这里拆开了，那么在主从复制中，从库就可能分段去执行同一个事务的多个操作，就破坏了原子性。然后，这里也不是直接把binlog cache里的内容持久化到磁盘上的binlog日志的。在默认情况下，每次事务提交时候只会把binlog cache的内容通过write方法写到文件系统的page cache中，然后后面再由操作系统决定什么时候把page cache里的内容通过fsync方法持久化到磁盘的binlog文件里，也就是刷盘。这里write并不会涉及到磁盘的IO操作，所以速度还是比较快。然后，mysql提供了一个参数叫sync_binlog能设置这样的刷盘频率。比如，刚刚说的默认情况下他设置的是0，它性能是最好的，但是风险也很大，如果还没有刷盘时候操作系统主机关机重启了，那就会丢失数据。还能设置1，设置1的时候每次事务提交执行write后，就会马上执行fsync去刷盘。这时候就会很安全，但性能也会损耗很大。还能设置为N，这里N要大于1，就是说可以等积累了N个事务后再一起fsync刷盘。

## binlog和redolog区别

首先，binlog是server层实现的日志，而redolog是innodb存储引擎层实现的日志。然后，它们的文件格式也有区别，binlog写入的文件格式主要有三种可以选择，分别是STATEMENT这个是默认模式，还有ROW和 MIXED。STATEMENT模式下，它记录的是逻辑sql，比如，你执行了一条更新语句，那他就会把这条语句原模原样的记下来。这种模式下有一个动态函数的问题，就是比如你在sql语句中用了uuid或者now这样的函数，那么在主从复制中，从库执行这条sql语句得到的结果就会的主库不一样。row模式它就不再记录逻辑sql了，它会记录数据最终被修改成什么样。比如，有一条更新sql语句，改变了好几行数据，那他就会把这几行改变之后的结果都记录下来，这样就不会出现刚刚说的动态函数的问题了。但这样有可能导致binlog文件太大。还有一种就是mixed模式，就是把这两种模式混合起来用。然后，redolog他记录的是物理日志，而不是这样一条条的sql语句或者数据库中的一行行数据。比如，修改数据后，它会记录在哪个表空间中的哪个数据页中的什么偏移量的地方做了什么更新。还有一个区别是他们写入文件的方式会不一样，binlog是追加写的方式，比如先在一个文件里一直往后面写，写满后就再写到第二个文件里，不会删除前面那个文件，所以他记录的是全量的数。但是redolog采用的是循环写的方式，比如有两个redolog文件，先写第一个文件，第一个文件写满后，写第二个，第二个又写满后，他就会又重新在文件一中写，就是这样一个循环的方式。

# MVCC

Multi-Version Concurrency Control，多版本并发控制

它可以用来维护一个数据的多个版本，那么，多个事务同时读写同一行数据时候，就不会相互阻塞了，因为他们可以通过mvcc看到他们需要的各自不同版本的数据。mvcc的具体实现主要依赖两个东西，一个是版本链，一个是ReadView。首先，我先讲一下版本链是啥吧。当我们创建一个表时候，每一行数据除了我们创建的那些字段，还会有两个隐藏字段，一个是DB_TRX_ID，用来记录最近一次是哪个事务修改的这条记录。还有一个是DB_ROLL_PTR，他是一个回滚指针，指向这条记录的上一个版本，它得配合undo log日志来实现，因为undo log里就记录的是你这条记录的修改之前是啥样的，也就是它的上一个版本。那么，通过这个最近修改的事务的id和这个回滚指针，我们就能构建出这条记录的一个版本链。然后，还有一个很重要的东西，叫readview读视图。这个读视图主要有四个核心的字段，一个是当前活跃的事务id集合，一个是最小活跃事务id，一个是预分配事务id，也就是当前最大的事务id+1，还有一个是这个readview创建者的事务id。那么，当我们进行读操作时候，他会生成一个readview，然后我们沿着要读的这条记录的版本链找下去，拿版本链中每一条记录的那个TRX_ID和readview中的这几个字段的值对比，从而找到我们可以读到的那条记录。比如，如果TRX_ID小于最小活跃事务的id，那就代表这条数据的这个版本已经被提交了，是可以访问的，如果大于最大事务活跃id，就代表这条数据是在生成readview之后才生成的，就不能访问版本链中的这条记录。如果TRX_ID大于最小活跃事务的id，又小于最大事务活跃id，那么还要判断一下它在不在那个当前活跃的事务id的集合里。如果不在的话，才能访问这条记录的这个版本。所以通过版本链和readview就可以实现mvcc多版本并发控制。通过mvcc就可以实现事务的隔离，比如，对于快照读也就是普通的select语句，在RC读提交隔离级别下，会在事务中每一次读操作时都生成ReadView，所以同一个事务中的两个readview有可能不一样，那么它在同一个事务中两次读操作就可能读到不一样的值。而在RR可重复读隔离级别下，它会在事务中第一次读操作时候生成ReadView，后面都复用这个ReadView，那么由于readview是一样的，它在同一个事务中两次读操作就一定找到的是同一个版本的数据，读到的数据肯定是相同的。

# update具体流程

首先，优化器确定好执行计划后，执行器就调用存储引擎的接口去执行，存储引擎就去查要更新的这条记录，如果这条记录所在的数据页在缓冲池里，那就直接返回给执行器去更新，如果不在，那就从磁盘加载一下再返回给执行器去更新。执行器拿到这条记录后，会先看一下更新前后的数据一不一样，一样的话就啥都不做直接返回给客户端了。如果不一样，那就再去调innodb的接口，把更新前后的值都作为参数传过去。然后就是innodb真正执行更新的流程了，首先就是先开启事务，然后在更新之前要先记录对应的undo log，比如这是更新操作，就要把对应的旧值记下来，这条undolog是先写到缓冲池的undo页里，然后再在redo log bufer里去记录对应这条undo log的redo log日志，也就是为了保证undo log的持久性。然后，正式开始更新数据，先更新缓冲池里的数据，把对应的页标记为脏页，然后同样也是写对应的redolog。写完redolog后，就已经算更新完成了。后面再由一个后台线程把脏页刷新到磁盘里。最后，在事务提交之前，还要把这条更新语句对应的binlog 记录到binlog cache里。然后等事务提交时候，根据设置的binlog刷盘策略去刷盘。























































